{"meta":{"title":"Z's blog","subtitle":"最可怕一生碌碌无为，还说平凡难能可贵！","description":null,"author":"Z","url":"https://zealforbeing.github.io"},"pages":[{"title":"关于我","date":"2018-03-22T08:10:20.000Z","updated":"2018-03-22T08:57:35.000Z","comments":false,"path":"about/index.html","permalink":"https://zealforbeing.github.io/about/index.html","excerpt":"","text":""},{"title":"分类","date":"2018-03-22T08:04:11.000Z","updated":"2018-03-22T08:51:38.148Z","comments":false,"path":"categories/index.html","permalink":"https://zealforbeing.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2018-03-22T07:56:32.000Z","updated":"2018-03-22T08:02:10.910Z","comments":true,"path":"tags/index.html","permalink":"https://zealforbeing.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"摄像头采集图像","slug":"iOS/视音频/摄像头采集图像","date":"2018-11-29T06:33:32.000Z","updated":"2018-12-10T03:57:48.425Z","comments":true,"path":"2018/11/29/iOS/视音频/摄像头采集图像/","link":"","permalink":"https://zealforbeing.github.io/2018/11/29/iOS/视音频/摄像头采集图像/","excerpt":"","text":"前言主要API AVCaptureDevice //输入设备，摄像头或者麦克风 AVCaptureInput //用于配置输入端口 AVCaptureOutput //用于管理输出视频或者静态图片 AVCaptureSession //用于协调从输入到输出的数据流 AVCaptureVideoPreviewLayer //实时预览摄像头采集的图片数据 AVCaptureSession初始化 &amp; 设置分辨率AVCaptureSession的初始化仅仅是初始化一个实例对象，分辨率一般测试用直播使用AVCaptureSessionPreset640x480已经足够，后期可以根据需求设置 1234567//初始化sessionself.session = [[AVCaptureSession alloc] init];//设置摄像头的分辨率640*480if ([self.session canSetSessionPreset:AVCaptureSessionPreset640x480]) &#123; self.session.sessionPreset = AVCaptureSessionPreset640x480;&#125; AVCaptureSessionPresetHigh //Highest recording quality. This varies per device. AVCaptureSessionPresetMedium //Suitable for Wi-Fi sharing. The actual values may change. AVCaptureSessionPresetLow //Suitable for 3G sharing. The actual values may change. AVCaptureSessionPreset640x480 //VGA. AVCaptureSessionPreset1280x720 //720p HD. AVCaptureSessionPresetPhoto //Full photo resolution. This is not supported for video output. AVCaptureDevice初始化 &amp; 自动变焦使用默认方式获取到的摄像头是后置，如果需要获取前置要遍历所有摄像头设备，找到[device position] == AVCaptureDevicePositionFront。 1234567891011121314//默认获取后置摄像头self.videoDevice = [AVCaptureDevice defaultDeviceWithMediaType:AVMediaTypeVideo];or //遍历所有视频采集设备NSArray *devices = [AVCaptureDevice devicesWithMediaType:AVMediaTypeVideo];for (AVCaptureDevice *device in devices) &#123; //找到前置摄像头 if ([device position] == AVCaptureDevicePositionFront) &#123; self.videoDevice = device; break; &#125;&#125; 拍摄动态视频都是要自动变焦的，我们用到支持自动变焦AVCaptureFocusModeContinuousAutoFocus 注意：要在设备上设置捕获属性，必须首先使用lockForConfiguration:获取设备上的锁。这避免了做出可能与其他应用程序中的设置不兼容的更改。 123456789//自动变焦if([self.videoDevice isFocusModeSupported:AVCaptureFocusModeContinuousAutoFocus])&#123; NSError *error; BOOL isLooked = [self.videoDevice lockForConfiguration:&amp;error]; if(isLooked &amp;&amp; error == nil)&#123; self.videoDevice.focusMode = AVCaptureFocusModeContinuousAutoFocus; [self.videoDevice unlockForConfiguration]; &#125;&#125; 设置帧率帧率可以动态去设置，self.videoDevice.activeFormat.videoSupportedFrameRateRanges可以获取到摄像头帧率的支持范围，设置时同样需要对设备上锁。 12345678910111213141516//在设置帧率之前先获取帧率支持范围NSLog(@\"支持的帧速范围是: %@\",[self.videoDevice.activeFormat.videoSupportedFrameRateRanges objectAtIndex:0]);//设置帧速NSError *error;BOOL isLocked = [self.videoDevice lockForConfiguration:&amp;error];if (isLocked &amp;&amp; error == nil) &#123; if (self.videoDevice.activeFormat.videoSupportedFrameRateRanges)&#123; [self.videoDevice setActiveVideoMinFrameDuration:CMTimeMake(1, fps)]; [self.videoDevice setActiveVideoMaxFrameDuration:CMTimeMake(1, fps)]; &#125; [self.videoDevice unlockForConfiguration];&#125; 其他设置12345678910111213141516171819202122232425//输出设置self.videoDataOutput = [[AVCaptureVideoDataOutput alloc] init];//kCVPixelFormatType_420YpCbCr8BiPlanarVideoRange 表示原始数据的格式为YUV420NSDictionary *settings = [[NSDictionary alloc] initWithObjectsAndKeys:[NSNumber numberWithUnsignedInt:kCVPixelFormatType_420YpCbCr8BiPlanarVideoRange], kCVPixelBufferPixelFormatTypeKey, nil];self.videoDataOutput.videoSettings = settings;//保证不会在结束录制时卡顿，丢弃最后的视频帧self.videoDataOutput.alwaysDiscardsLateVideoFrames = YES;//创建输出处理队列_videoQueue = dispatch_queue_create(\"VideoQueue\", DISPATCH_QUEUE_SERIAL);//指定输出监听代理及队列[self.videoDataOutput setSampleBufferDelegate:self queue:_videoQueue];if([self.session canAddOutput:self.videoDataOutput])&#123; [self.session addOutput:self.videoDataOutput];&#125;//获取输出连接self.videoConnection = [self.videoDataOutput connectionWithMediaType:AVMediaTypeVideo];//设置输出图像的方向self.videoConnection.videoOrientation = AVCaptureVideoOrientationPortrait; 代理方法处理采集到的画面12345678910111213#pragma mark - AVCaptureVideoDataOutputSampleBufferDelegate /* CMSampleBufferRef: 帧缓存数据，描述当前帧信息 CMSampleBufferGetXXX : 获取帧缓存信息 CMSampleBufferGetDuration : 获取当前帧播放时间 CMSampleBufferGetImageBuffer : 获取当前帧图片信息 */ // 获取帧数据 - (void)captureOutput:(AVCaptureOutput *)output didOutputSampleBuffer:(CMSampleBufferRef)sampleBuffer fromConnection:(AVCaptureConnection *)connection &#123; // captureSession 会话如果没有强引用，这里不会得到执行 NSLog(@\"----- sampleBuffer ----- %@\", sampleBuffer); &#125; 参考《iOS - 视频采集详解》《Still and Video Media Capture》","categories":[{"name":"iOS","slug":"iOS","permalink":"https://zealforbeing.github.io/categories/iOS/"}],"tags":[{"name":"视音频","slug":"视音频","permalink":"https://zealforbeing.github.io/tags/视音频/"}],"keywords":[{"name":"iOS","slug":"iOS","permalink":"https://zealforbeing.github.io/categories/iOS/"}]},{"title":"视音频开发-YUV420P","slug":"iOS/视音频/视音频开发-YUV420P","date":"2018-04-18T08:36:57.000Z","updated":"2018-04-22T03:53:22.000Z","comments":true,"path":"2018/04/18/iOS/视音频/视音频开发-YUV420P/","link":"","permalink":"https://zealforbeing.github.io/2018/04/18/iOS/视音频/视音频开发-YUV420P/","excerpt":"","text":"前言对一种颜色进行编码的方法统称为”颜色空间”或”色域”，RGB和YUV，都是颜色空间的种类。iOS中获取到的摄像头的原始数据，常见也就是RGB和YUV。RGB可能大家都比较熟，就是每个像素由三原色分量组成，在计算机存储中三个分量的值在0~255之间。YUV也是有三个分量的，只是存储的信息与RGB是完全不一样的。 YUV简介YUV（亦称YCrCb）是被欧洲电视系统所采用的一种颜色编码方法（属于PAL）。YUV主要用于优化彩色视频信号的传输，使其向后兼容老式黑白电视。主要用于电视系统以及模拟视频领域，它将亮度信息（Y）与色彩信息（UV）分离，没有UV信息一样可以显示完整的图像，只不过是黑白的，这样的设计很好地解决了彩色电视机与黑白电视的兼容问题。与RGB视频信号传输相比，它最大的优点在于只需占用极少的带宽（RGB要求三个独立的视频信号同时传输）。 YUV格式有两大类：planar和packed。 对于planar的YUV格式，先连续存储所有像素点的Y，紧接着存储所有像素点的U，随后是所有像素点的V。 对于packed的YUV格式，每个像素点的Y,U,V是连续交*存储的。 YUV，分为三个分量，“Y”表示明亮度（Luminance或Luma），也就是灰度值；而“U”和“V” 表示的则是色度（Chrominance或Chroma），作用是描述影像色彩及饱和度，用于指定像素的颜色。YUV码流的存储格式其实与其采样的方式密切相关，主流的采样方式有三种，YUV4:4:4，YUV4:2:2，YUV4:2:0，如图1所示，以黑点表示采样该像素点的Y分量，以空心圆圈表示采用该像素点的UV分量。 图1、主流YUV采样图 按照图1所示，每种采样的区别在于YUV分量的比例，我们知道仅有Y分量就可以组成一幅完整的黑白画面，UV控制的是色彩和饱和度，降低UV的采样率并不会明显降低视觉质量，只是色度会减弱。 YUV 4:4:4采样，每一个Y对应一组UV分量。 YUV 4:2:2采样，每两个Y共用一组UV分量。 YUV 4:2:0采样，每四个Y共用一组UV分量。 YUV420P结构分析YUV420P结构比较简单，应用比较广泛。在YUV420P中，P代表planar，意味着像素点的YUV都是是分开存储的，还可以分为I420和YV12。I420格式和YV12格式的不同处在U平面和V平面的位置： I420: YYYYYYYY UU VV =&gt;YUV420P YV12: YYYYYYYY VV UU =&gt;YUV420P 图2、YUV420P I420结构图 在内存中是以Y1 Y2 ... Y32 U1 U2 ... U8 V1 V2 ... V8去存储的，所以必须要知道图片宽度才能正确解析出。图2中排法让我们更直观的看出分量间的关系，不同的色块对应着不同的组合关系，比如Y1、Y2、Y9、Y10对应的UV采集为U1、V1。 YUV420P与RGB24的转化显示设备都是RGB的三原色显示标准，想要在屏幕中显示YUV图像需要将其转为RGB图像，转换是通过公式计算的方式完成的，在网上搜索会出现很多公式，有些就差小数点几位，但是都能正常地转化。至于为什么这么多种，可以参考一下《YUV与RGB互转各种公式 (YUV与RGB的转换公式有很多种，请注意区别！！！)》这篇文章，差小数点后几位的真的不知道哪里来的差别。。。 这里就用雷神程序里的计算公式吧： YUV420P -&gt; RGB24 123R = Y + ( 1.4075 * (V - 128) ); G = Y - ( 0.3455 * (U - 128) - 0.7169 * (V - 128) ); B = Y + ( 1.7790 * (U - 128) ); RGB24 -&gt; YUV420P 123Y= 0.299 * R + 0.587 * G + 0.114 * BU= -0.147 * R - 0.289 * G + 0.463 * BV= 0.615 * R - 0.515 * G - 0.100 * B YUV420P生成与显示了解完YUV420P的存储方式以及转化显示原理，可以找一张图片过来试试，也可以自己手动生成一张图片，验证一下以上的理论。这里我直接拿雷神的生成YUV420P格式的灰阶测试图程序来验证。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970/** * Generate YUV420P gray scale bar. * @param width Width of Output YUV file. * @param height Height of Output YUV file. * @param ymin Max value of Y * @param ymax Min value of Y * @param barnum Number of bars * @param url_out Location of Output YUV file. */ int simplest_yuv420_graybar(int width, int height,int ymin,int ymax,int barnum,char *url_out)&#123; int barwidth; float lum_inc; unsigned char lum_temp; int uv_width,uv_height; FILE *fp=NULL; unsigned char *data_y=NULL; unsigned char *data_u=NULL; unsigned char *data_v=NULL; int t=0,i=0,j=0; barwidth=width/barnum; lum_inc=((float)(ymax-ymin))/((float)(barnum-1)); uv_width=width/2; uv_height=height/2; data_y=(unsigned char *)malloc(width*height); data_u=(unsigned char *)malloc(uv_width*uv_height); data_v=(unsigned char *)malloc(uv_width*uv_height); if((fp=fopen(url_out,\"wb+\"))==NULL)&#123; printf(\"Error: Cannot create file!\"); return -1; &#125; //Output Info 打印YUV分量 printf(\"Y, U, V value from picture's left to right:\\n\"); for(t=0;t&lt;(width/barwidth);t++)&#123; lum_temp=ymin+(char)(t*lum_inc); printf(\"%3d, 128, 128\\n\",lum_temp); &#125; //Gen Data //存储Y分量 for(j=0;j&lt;height;j++)&#123; for(i=0;i&lt;width;i++)&#123; t=i/barwidth; lum_temp = ymin + (char)(t * lum_inc); data_y[j*width+i]=lum_temp; &#125; &#125; //存储U分量 for(j=0;j&lt;uv_height;j++)&#123; for(i=0;i&lt;uv_width;i++)&#123; data_u[j*uv_width+i]=128; &#125; &#125; //存储V分量 for(j=0;j&lt;uv_height;j++)&#123; for(i=0;i&lt;uv_width;i++)&#123; data_v[j*uv_width+i]=128; &#125; &#125; fwrite(data_y,width*height,1,fp); fwrite(data_u,uv_width*uv_height,1,fp); fwrite(data_v,uv_width*uv_height,1,fp); fclose(fp); free(data_y); free(data_u); free(data_v); return 0; &#125; 调用如下，传入宽高、Y分量的取值范围以及灰度条的个数，这里传了10，最后一个参数是生成图片的存储路径。程序中我们看到，Y分量根据不同的灰度递增，U和V都为128，根据转换公式，在转为RGB时RGB分量都取值Y。也可以随意修改UV值看能得出一个什么样的图片，进一步地理解。关于YUV图像的更多处理请参考《视音频数据处理入门：RGB、YUV像素数据处理》。 1simplest_yuv420_graybar(640, 360, 0, 255, 10, \"graybar_640x360.yuv\"); 显示也是参考雷神《最简单的视音频播放示例5：OpenGL播放RGB/YUV》，这里截出转化的代码，其余部分可以去雷神的博客看看，比较浅显易懂。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647inline unsigned char CONVERT_ADJUST(double tmp) &#123; return (unsigned char)((tmp &gt;= 0 &amp;&amp; tmp &lt;= 255)?tmp:(tmp &lt; 0 ? 0 : 255)); &#125; //YUV420P to RGB24 void CONVERT_YUV420PtoRGB24(unsigned char* yuv_src,unsigned char* rgb_dst,int nWidth,int nHeight) &#123; unsigned char *tmpbuf=(unsigned char *)malloc(nWidth*nHeight*3); unsigned char Y,U,V,R,G,B; unsigned char* y_planar,*u_planar,*v_planar; int rgb_width , u_width; rgb_width = nWidth * 3; u_width = (nWidth &gt;&gt; 1); int ypSize = nWidth * nHeight; int upSize = (ypSize&gt;&gt;2); int offSet = 0; y_planar = yuv_src; u_planar = yuv_src + ypSize; v_planar = u_planar + upSize; for(int i = 0; i &lt; nHeight; i++) &#123; for(int j = 0; j &lt; nWidth; j ++) &#123; // Get the Y value from the y planar Y = *(y_planar + nWidth * i + j); // Get the V value from the u planar offSet = (i&gt;&gt;1) * (u_width) + (j&gt;&gt;1); V = *(u_planar + offSet); // Get the U value from the v planar U = *(v_planar + offSet); // Cacular the R,G,B values R = CONVERT_ADJUST((Y + (1.4075 * (V - 128)))); G = CONVERT_ADJUST((Y - (0.3455 * (U - 128) - 0.7169 * (V - 128)))); B = CONVERT_ADJUST((Y + (1.7790 * (U - 128)))); offSet = rgb_width * i + j * 3; rgb_dst[offSet] = B; rgb_dst[offSet + 1] = G; rgb_dst[offSet + 2] = R; &#125; &#125; free(tmpbuf); &#125; 图3、YUV灰阶测试图显示 后话这里只是对YUV420P图像结构的基本了解，往后YUV图像采集和播放有一定的认识。终于也对大学时学的MATLAB函数有点了解，如果当初先了解这些，也许我会更有兴趣学习图像处理吧。 参考《最简单的视音频播放示例5：OpenGL播放RGB/YUV》 《视音频数据处理入门：RGB、YUV像素数据处理》 《图文详解YUV420数据格式》 《从零开始学习音视频编程技术（十五） YUV420P转RGB32》 《YUV与RGB互转各种公式 (YUV与RGB的转换公式有很多种，请注意区别！！！)》","categories":[{"name":"iOS","slug":"iOS","permalink":"https://zealforbeing.github.io/categories/iOS/"}],"tags":[{"name":"视音频","slug":"视音频","permalink":"https://zealforbeing.github.io/tags/视音频/"}],"keywords":[{"name":"iOS","slug":"iOS","permalink":"https://zealforbeing.github.io/categories/iOS/"}]},{"title":"视音频学习计划","slug":"iOS/视音频/视音频学习计划","date":"2018-04-12T07:54:31.000Z","updated":"2018-04-19T03:02:03.393Z","comments":true,"path":"2018/04/12/iOS/视音频/视音频学习计划/","link":"","permalink":"https://zealforbeing.github.io/2018/04/12/iOS/视音频/视音频学习计划/","excerpt":"","text":"前言初学视音频，并不能面面俱到，把每种协议、格式、编码都学一遍。这里计划在众多流媒体协议、视频格式、视音频编码格式中各挑出几种，在iOS端实现一些小功能，理论还是需要结合实际。 选择视频播放流程图在《视频播放简单原理》已经介绍过：解协议-&gt;解封装-&gt;解编码-&gt;音画同步-&gt;输出。 对应的选择 解协议 &gt;&gt; rtmp &amp; http 解封装 &gt;&gt; flv &amp; mp4 解编码 &gt;&gt; H264 &amp; AAC 输出 &gt;&gt; YUV &amp; RGB &amp; PCM 选择的原因 rtmp（Real Time Messaging Protocol）是实时传输协议，即偏向于做直播这种有实时要求的内容，由于之前项目有过相关了解，想要更深入了解； http作为流媒体时，对flv文件格式的支持较好，更容易实现视频的点播观看，各大视频网站都采用； flv是Adob公司出品，无论是rtmp还是http对其的支持都比较好； mp4比较流行； H264比较流行，应用广泛； AAC比较流行，应用广泛； YUV &amp; RGB &amp; PCM比较流行，应用广泛； 学习规划初步的计划是做一个利用摄像头和麦克风采集视音频，编码-&gt;封装-&gt;保存-&gt;解封装-&gt;解码-&gt;播放，这个过程主要学习编码与封装。后期加入实时推流、拉流、点播功能，学习流媒体协议。 摄像头采集图像 编码视频：YUV -&gt; H264 解码视频：H264 -&gt; YUV （播放） 编码音频：PCM -&gt; AAC 解码音频：AAC -&gt; PCM （播放） 同步音视频 封装 \b","categories":[{"name":"iOS","slug":"iOS","permalink":"https://zealforbeing.github.io/categories/iOS/"}],"tags":[{"name":"视音频","slug":"视音频","permalink":"https://zealforbeing.github.io/tags/视音频/"}],"keywords":[{"name":"iOS","slug":"iOS","permalink":"https://zealforbeing.github.io/categories/iOS/"}]},{"title":"视频播放简单原理","slug":"iOS/视音频/视频播放简单原理","date":"2018-04-12T01:38:00.000Z","updated":"2018-04-19T03:02:09.328Z","comments":true,"path":"2018/04/12/iOS/视音频/视频播放简单原理/","link":"","permalink":"https://zealforbeing.github.io/2018/04/12/iOS/视音频/视频播放简单原理/","excerpt":"","text":"前言 视频播放基本流程 基本概念 常用流媒体协议 常用封装 视频编码 音频编码 音画同步 后话 参考 前言前段时间做了一个直播模块，没有意外都是用第三方服务实现的，基本都是业务的东西，有时间就开始研究下相关的技术，不能一直做黑盒程序猿啊。这篇文章主要是记录视频播放的简单原理，很多内容都是摘录自雷神等人的博客，希望不会被怪罪。想要深入研究很推荐去雷神的专栏看一下(https://blog.csdn.net/leixiaohua1020)，在此缅怀这位无私智者。 视频播放基本流程图1、视频播放流程图 解协议：将流媒体协议的数据，解析为标准的相应的封装格式数据，常用协议：HTTP、RTMP、MMS等； 解封装：将输入的封装格式的数据，分离成为音频流压缩编码数据和视频流压缩编码数据，常见视频格式：MP4、MKV、FLV、RMVB等 解码（视、音频解码）：将视频/音频压缩编码数据，解码成为非压缩的视频/音频原始数据，常见解码：视频编码H264-&gt;像素数据YUV/RGB、音频编码AAC-&gt;采样数据PCM 音画同步：根据解封装模块处理过程中获取到的参数信息，同步解码出来的视频和音频数据，并将视频音频数据送至系统的显卡和声卡播放出来，以FFmpeg库为例，利用时间戳去同步二者：PTS（Presentation Time Stamp 显示时间戳）、DTS（Decoding Time Stamp 解码时间戳）； 终端设备播放：显卡、声卡对视（YUV、RGB）音频（PCM）的输出。 基本概念 分辨率：指每一帧画面的大小,宽乘高等于若干像素。目前主流的高清格式通常为：720p（1280×720）、1080p（1920×1080）、2K（2560x1440）、4K（4096×2160） 码率（比特率，bit per second / bps / bit rate）：指单位时间传输的或解码的位数。码率越大，说明单位时间内取样率越大，数据流精度就越高，这样表现出来的的效果就是：视频画面更清晰画质更高。 帧率（frames per seconds / fps）：指播放时每秒移动多少帧。通常说一个视频的25帧，指的就是这个视频帧率，即1秒中会显示25帧；视频帧率影响的是画面流畅感，也就是说视频帧率超高，表现出来的效果就是：画面越显得流畅。一般NTSC①是30,PAL②是25，帧速太低则画面不连续播放的流畅性就差，所以要恰到好处才行。 采样率（sample rate）：指每秒采集的次数，这个是指音频的，采的越多，声音质量越好，当然体积也会大。 码率影响体积，与体积成正比；码率越大，体积越大；码率越小，体积越小。帧率影响画面流畅度，与画面流畅度成正比：帧率越大，画面越流畅；帧率越小，画面越有跳动感。如果码率为变量，则帧率也会影响体积，帧率越高，每秒钟经过的画面越多，需要的码率也越高，体积也越大。分辨率影响图像大小，与图像大小成正比：分辨率越高，图像越大；分辨率越低，图像越小。 常用流媒体协议不管是观看视频还是直播，大多数都需要通过网络传播，服务器与客户端都需要遵循一定的协议才能实现数据的传输与解析。目前已经有很多流媒体协议（如表1所示），各有优劣，将来还会有更多的机构制定、推出不同的协议，以解决现有的问题。基于TCP的协议传输可靠，但是会有抖动、延迟等问题。基于UDP的协议虽然抖动和延迟情况会好些，但是不够可靠存在丢包的情况。所以不能说哪个协议最好，只能根据自身业务需求选择一种适合的协议，亦或是自行制定协议，在封装可靠的UDP连接等。 表1、常见流媒体协议 名称 推出机构 传输层协议 客户端 目前使用领域 RTSP+RTP IETF TCP+UDP VLC, WMP IPTV RTMP Adobe Inc. TCP Flash 互联网直播 RTMFP Adobe Inc. UDP Flash 互联网直播 MMS Microsoft Inc. TCP/UDP WMP 互联网直播+点播 HTTP WWW+IETF TCP Flash 互联网点播 HLS Apple Inc. TCP iOS, macOS 互联网直播+点播 常用封装一般我们所说的视频包括画面和声音，二者分开的话顶多算是图片和音频，封装便是把画面和声音打包到一起组成视频文件，解封装便是打包的逆过程，将画面和声音分开，播放是交给不同的设备输出。视频封装同样有很多格式，平时都是以文件后缀就可以区分，如常见的：.mp4、.flv、.rmvb等等。支持不同的音视频编码决定其最终的画质和音质；支持流媒体协议与否，决定其能不能以流媒体形式传输。 表2、常见视频封装格式 名称 推出机构 流媒体 支持的视频编码 支持的音频编码 目前使用领域 AVI Microsoft Inc. 不支持 几乎所有格式 几乎所有格式 BT下载影视 MP4 MPEG 支持 MPEG-2, MPEG-4, H.264, H.263等 AAC, MPEG-1 Layers I, II, III, AC-3等 互联网视频网站 TS MPEG 支持 MPEG-1, MPEG-2, MPEG-4, H.264 MPEG-1 Layers I, II, III, AAC, IPTV，数字电视 FLV Adobe Inc. 支持 Sorenson, VP6, H.264 MP3, ADPCM, Linear PCM, AAC等 互联网视频网站 MKV CoreCodec Inc. 支持 几乎所有格式 几乎所有格式 互联网视频网站 RMVB Real Networks Inc. 支持 RealVideo 8, 9, 10 AAC, Cook Codec, RealAudio Lossless BT下载影视 视频编码如果视频中每一帧的画面都是原图片的话，最后生成的视频将是巨大的。在一些视频中往往会有一段时间，画面的大部分内容都是相同的，这个时候就可以进行前后画面的对比，进行一定的压缩操作以达到节省空间的作用，这种压缩操作就是视频编码。不同的压缩算法，就产生了不同的编码格式，应用的比较广泛的就是H.264了，接下来也会深入的去学习一下。 表3、常见视频编码 名称 推出机构 推出时间 目前使用领域 HEVC(H.265) MPEG/ITU-T 2013 研发中 H.264 MPEG/ITU-T 2003 各个领域 MPEG4 MPEG 2001 不温不火 MPEG2 MPEG 1994 数字电视 VP9 Google 2013 研发中 VP8 Google 2008 不普及 VC-1 Microsoft Inc. 2006 微软平台 音频编码音频编码和视频编码的道理一个样，对原始音频数据的压缩，为的也是节省空间，AAC和MP3应用广泛。 表4、常见音频编码 名称 推出机构 推出时间 目前使用领域 AAC MPEG 1997 各个领域（新） AC-3 Dolby Inc. 1992 电影 MP3 MPEG 1993 各个领域（旧） WMA Microsoft Inc. 1999 微软平台 音画同步音视频是不同设备去采集，音视频编码解码时间不一致，流媒体传输将音视频分开传输等等原因，不作处理，声音和画面播放往往是不同步的，直接播放肯定是没法看的。采集的时候需要给每个视频帧和音频样本加上时间戳，再通过一个基准将音画进行同步处理，解决方案有如下几种： 将视频同步到音频上，就是以音频的播放速度为基准来同步视频。视频比音频播放慢了，加快其播放速度；快了，则延迟播放。 将音频同步到视频上，就是以视频的播放速度为基准来同步音频。 将视频和音频同步外部的时钟上，选择一个外部时钟为基准，视频和音频的播放速度都以该时钟为标准。 后话经过一段时间的学习，反反复复看雷神的博客，写了些代码实践验证，音视频这个领域广度和深度是我无法想象的，还是要靠慢慢的积累。文中有什么错误和不足欢迎指正。 参考《视音频编解码技术零基础学习方法》《FFMPEG编码：参数研究》《FFmpeg学习6：视音频同步》","categories":[{"name":"iOS","slug":"iOS","permalink":"https://zealforbeing.github.io/categories/iOS/"}],"tags":[{"name":"视音频","slug":"视音频","permalink":"https://zealforbeing.github.io/tags/视音频/"}],"keywords":[{"name":"iOS","slug":"iOS","permalink":"https://zealforbeing.github.io/categories/iOS/"}]},{"title":"iOS知识梳理","slug":"iOS/iOS知识梳理","date":"2018-03-26T09:36:21.000Z","updated":"2018-03-27T01:48:22.646Z","comments":true,"path":"2018/03/26/iOS/iOS知识梳理/","link":"","permalink":"https://zealforbeing.github.io/2018/03/26/iOS/iOS知识梳理/","excerpt":"","text":"","categories":[{"name":"iOS","slug":"iOS","permalink":"https://zealforbeing.github.io/categories/iOS/"}],"tags":[{"name":"iOS","slug":"iOS","permalink":"https://zealforbeing.github.io/tags/iOS/"}],"keywords":[{"name":"iOS","slug":"iOS","permalink":"https://zealforbeing.github.io/categories/iOS/"}]},{"title":"博客的艰难部署过程","slug":"工具/博客的艰难部署过程","date":"2018-03-22T06:15:05.000Z","updated":"2018-03-26T09:11:57.429Z","comments":true,"path":"2018/03/22/工具/博客的艰难部署过程/","link":"","permalink":"https://zealforbeing.github.io/2018/03/22/工具/博客的艰难部署过程/","excerpt":"","text":"Hexo + GitHub Pages 搭建个人博客 Hexo + GitHub Pages 搭建个人博客 1. 前言 2. 搭建步骤 3. 搭建 Node.js 环境 4. 搭建Git环境 &amp; GitHub注册和配置 5. 安装配置 Hexo 6. 关联 Hexo 与 GitHub Pages 6.1 生成SSH Keys 6.2 添加 SSH Key 到 GitHub 6.3 测试 6.4 配置信息 7. Hexo 的常用操作 8. Hexo 主题 9. 解决多端同步问题 10. 后话 11. 参考 1. 前言对于一个强迫症患者来说，搭建个人博客是一件让人抓狂的事情。四处寻找主题，有的是功能不全，没有分类和标签；有的是样式太随便，字体和布局都不大满意，对于一个不熟悉前端的人来说，修改样式有点费时间；还有就是环境问题，很多教程都是博客老手写出来的，有些细节点并没有很好的说明。仅以此文记录自己在 macOS环境 中安装的步骤和遇到的问题，如有其它问题欢迎交流。 2. 搭建步骤这次介绍的是使用 Hexo + GitHub Pages 搭建个人博客。Hexo是基于Nodejs的框架，一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。再使用GitHub托管就能免费搭建个人博客。 123456781. 搭建 Node.js 环境2. 搭建 Git 环境3. GitHub 注册和配置4. 安装配置 Hexo5. 关联 Hexo 与 GitHub Pages6. Hexo 的常用操作7. Hexo 主题8. 解决多端同步问题 3. 搭建 Node.js 环境前面说过Hexo是基于Nodejs的，所以必须要搭建Nodejs的环境，其中包括安装Nodejs编译环境和npm（JavaScript包管理工具）。搭建Nodejs环境的方法五花八门，不过可以大致分成几类： a. 下载Nodejs安装包，直接安装； 英文地址https://nodejs.org/en/； 中文地址http://nodejs.cn/download/。 b. 从克隆或者下载源码编译安装 使用命令$ sudo git clone https://github.com/nodejs/node.git将源码克隆到本地； 修改目录权限$ sudo chmod -R 755 node； 先后执行一下命令完成编译安装： 12345$ cd node$ sudo ./configure$ sudo make$ sudo make install$ node --version c. 利用包brew等管理工具安装，brew是macOS下的一个软件管理工具，因为网络长城和其他环境原因安装起来并不简单，可能需要换国内镜像，但是国内镜像也有出问题的时候，遇到问题还需要google 安装brew 1/usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot; 安装node和npm brew install node --with-npm 查看安装是否成功 12$ node -v$ npm -v 4. 搭建Git环境 &amp; GitHub注册和配置&ensp;&ensp;在macOS里面安装了Xcode就会附带安装Git，同时还有下载安装包和管理工具两种方式，这里附带下载地址http://git-scm.com/downloads，不做过多说明。 &ensp;&ensp;在GitHub（https://github.com/）注册一个账号就不用过多说明。&ensp;&ensp;配置就是要去建一个GitHub Pages的仓库，在GitHub Pages的主页是一句这样的介绍：Websites for you and your projects. 就是GitHub提供的一个存放静态网站的仓库，和普通仓库的区别就是它还能通过 https://username.github.io 域名来访问到这个网站。并没什么具体的步骤，只需要新建一个repository名字为username.github.io。 username一定要是你的用户名！ username一定要是你的用户名！ username一定要是你的用户名！ 5. 安装配置 Hexo 官网就有安装步骤，有时间可以去看下https://hexo.io/zh-cn/ 用npm安装hexo：npm install hexo-cli -g 安装完成查看版本信息，验证是否安装成功：hexo version 接下来就是配置你的个人博客 12345678910# 在本地创建一个hexo项目存放在username.github.io，这个和之前创建的仓库名一致$ hexo init username.github.io# 进入文件夹$ cd username.github.io# 把需要的依赖环境都自动装上$ npm install# 安装部署模块，有了这个模块才能使用 hexo d 部署到仓库中去，后面会讲$ npm install hexo-deployer-git --save# 安装启动服务模块，有了它才能在本地运行，预览效果$ npm install hexo-server --save 本地运行博客，预览效果 123$ hexo server或者$ hexo s 图1、博客的艰难部署过程/预览效果图 6. 关联 Hexo 与 GitHub Pages经过上一章节的操作，已经能够在本地写文章并且预览，现在就是要关联之前创建的GitHub Pages仓库，这样我就可以通过username.github.io 域名去访问。 6.1 生成SSH Keys输入一下命令，自己的邮箱地址&quot;xxxxxxxxxx@mail.com&quot;，ssh-keygen -t rsa表示我们指定 RSA 算法生成密钥。 $ ssh-keygen -t rsa -C &quot;xxxxxxxxxx@mail.com&quot; 执行后会要求输入密码，密码的话需要6位数以上，没有什么具体要求，不输入则是不需要密码。之后就就会生成两个文件，分别为id_rsa和id_rsa.pub，即密钥id_rsa和公钥id_rsa.pub。 6.2 添加 SSH Key 到 GitHub图2、添加SSH Key 首先要在个人GitHub的setting-&gt;SSH and GPG Keys(https://github.com/settings/ssh)中New SSH Key，在macOS中找到~/.ssh/id_rsa.pub，将id_rsa.pub中的内容复制到新建SSH Key的Key框中，点击ADD SSH Key即可。 6.3 测试执行以下命令查看是添加成功： 1$ ssh -T git@github.com 第一次执行clone或者push会有如下警告： 123The authenticity of host &apos;github.com (xx.xx.xx.xx)&apos; can&apos;t be established.RSA key fingerprint is xx.xx.xx.xx.xx.Are you sure you want to continue connecting (yes/no)? 这是因为Git使用SSH连接，而SSH连接在第一次验证GitHub服务器的Key时，需要你确认GitHub的Key的指纹信息是否真的来自GitHub的服务器，输入yes回车即可，得到一下信息即已经添加成功。 1Hi aierui! You&apos;ve successfully authenticated, but GitHub does not provide shell access. 6.4 配置信息Git 会根据用户的名字和邮箱来记录提交。GitHub 也是用这些信息来做权限的处理，输入下面的代码进行个人信息的设置，把名称和邮箱替换成你自己的。 12$ git config --global user.name &quot;username&quot;$ git config --global user.email &quot;xxxxx@mail.com&quot; 在博客更目录_config.yml文件中，找到Deployment，然后按照如下修改，用户名改成你的： 需要注意的是冒号后面记得空一格！ 123456# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo: git@github.com:username/username.github.io.git branch: master 7. Hexo 的常用操作结束了上面的配置，就可以开始写文章、渲染、发布，涉及的操作有： 123456789101112131415161718# 新建文章$ hexo new &quot;postName&quot;# 清除旧的发布文件$ hexo clean# 生成发布文件$ hexo generate或者$ hexo g# 本地预览hexo s# 发布$ hexo deploye或者$ hexo d 如果发布成功，就可以用 username.github.io 访问到你的博客，如果有自己的域名也可以配置成你的域名来访问，具体参考中的《可能是最详细的 Hexo + GitHub Pages 搭建博客的教程》有介绍。如果遇到错误，不妨看下以下几个问题。 注意1：发布前要安装发布扩张 1$ npm install hexo-deployer-git --save 注意2：如果在执行 hexo d 后,出现 error deployer not found:github 的错误（如下），则是因为没有设置好 public key 所致，重新详细设置即可。 1234Permission denied (publickey).fatal: Could not read from remote repository.Please make sure you have the correct access rightsand the repository exists. 注意3：怎么避免 .md 文件被解析？ Hexo原理就是hexo在执行hexo generate时会在本地先把博客生成的一套静态站点放到public文件夹中，在执行hexo deploy时将其复制到.deploy文件夹中。Github的版本库通常建议同时附上README.md说明文件，但是hexo默认情况下会把所有md文件解析成html文件，所以即使你在线生成了 README. md，它也会在你下一次部署时被删去。怎么解决呢？ 在执行hexo deploy前把在本地写好的README.md文件复制到.deploy文件夹中，再去执行hexo deploy。 8. Hexo 主题官方主题库：https://hexo.io/themes/ 主题是五花八门的，真正合心意的可能没几个，需要自己慢慢寻找。 纠结了很久之后用了https://github.com/shenliyang/hexo-theme-snippet这款。 123456789# 克隆主题到博客目录的themes/snippet文件夹下git clone git://github.com/shenliyang/hexo-theme-snippet.git themes/snippet# 安装主题渲染依赖插件npm install hexo-renderer-ejs --savenpm install hexo-renderer-less --save# 本地搜索支持插件npm install hexo-generator-json-content@2.2.0 -S 然后修改_config.yml中的theme: snippet，其他的配置可以看参考作者的GitHub，执行$ hexo clean、$ hexo generate、$ hexo s即可预览到修改主题后的效果，效果满意就可以进行发布。如果修改了某一个配置不起作用，不妨查看下是不是需要什么插件支持，对应地去安装插件。 9. 解决多端同步问题使用$ hexo d，将博客发布后，在GitHub仓库里就会发现，仓库只剩下hexo渲染后的静态网站，hexo和主题的代码都没有了，也许是因为hexo不想代码太混乱吧。这样的情况就会有个问题，我想在其他地方写文章或者换了部电脑，之前那些本地文件没有备份的话就得重头搭建了。解决这个问题有两种方法，一种是创建另外一个仓库存代码，不过这种方法总觉得很多余；所以第二种就是在原来的仓库新建一个分支，hexo命令来发布主干上的网站，git在分支上同步各端。 本地新建分支同步GitHub仓库 1234567891011121314151617181920# 初始化本地仓库（前面已创建可忽略）$ git init # 将必要的文件依次添加$ git add . # 提交修改$ git commit -m &quot;branch Hexo&quot;# 新建hexo分支$ git branch hexo # 切换到hexo分支上$ git checkout hexo # 将本地与Github项目对接（前面已执行可忽略）$ git remote add origin git@github.com:username/username.github.io.git # push到Github项目的hexo分支上$ git push origin hexo 在另一个电脑clone分支的代码 123456789101112131415161718192021# 将Github中hexo分支clone到本地$ git clone -b hexo git@github.com:username/username.github.io.git # 切换到刚刚clone的文件夹内$ cd username.github.io # 注意，这里一定要切换到刚刚clone的文件夹内执行，安装必要的所需组件，不用再init$ npm install # 新建一个.md文件，并编辑完成自己的博客内容$ hexo new post &quot;new blog name&quot; # 经测试每次只要更新sorcerer中的文件到Github中即可，因为只是新建了一篇新博客$ git add source $ git commit -m &quot;XX&quot;# 更新分支$ git push origin hexo # push更新完分支之后将自己写的博客对接到自己搭的博客网站上，同时同步了Github中的master$ hexo d -g 10. 后话GitHub Pages默认支持Jekyll+GitHub Pages的搭建，介绍：http://www.jekyll.com.cn/；搭建起来会更加简单些，折腾过才知道哪个更适合自己。 11. 参考 《可能是最详细的 Hexo + GitHub Pages 搭建博客的教程》 《hexo 博客搭建》 《hexo主题安装》 《如何解决github+Hexo的博客多终端同步问题》","categories":[{"name":"工具","slug":"工具","permalink":"https://zealforbeing.github.io/categories/工具/"}],"tags":[{"name":"macOS","slug":"macOS","permalink":"https://zealforbeing.github.io/tags/macOS/"},{"name":"Nodejs","slug":"Nodejs","permalink":"https://zealforbeing.github.io/tags/Nodejs/"}],"keywords":[{"name":"工具","slug":"工具","permalink":"https://zealforbeing.github.io/categories/工具/"}]}]}